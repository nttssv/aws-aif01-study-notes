<!-- Domain 4: Guidelines for Responsible AI of the AWS - Review Notes -->
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Domain 4 - Task 4.2: Explainable Models</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 2rem; line-height: 1.6; }
    h2 { color: #2c3e50; }
    ul { margin-top: 0.5rem; }
    li { margin-bottom: 0.5rem; }
    .section { margin-bottom: 2rem; }
  </style>
</head>
<body>

  <h2>ðŸ”¹ Understanding Responsible AI (related to Task 4.1)</h2>
  <ul>
    <li>Understand what <strong>Responsible AI</strong> is and its core principles.</li>
    <li>Identify features of responsible AI systems (e.g. fairness, safety, accountability).</li>
    <li>Know the tools that support responsible AI practices.</li>
    <li>Learn how responsible AI affects:
      <ul>
        <li>Model selection</li>
        <li>Risk assessment</li>
        <li>Dataset design and characteristics</li>
      </ul>
    </li>
    <li>Understand <strong>bias and variance</strong> in responsible AI context.</li>
    <li>Use tools to:
      <ul>
        <li>Detect bias</li>
        <li>Monitor model behavior</li>
        <li>Evaluate trustworthiness and truthfulness</li>
      </ul>
    </li>
  </ul>

  <h2>ðŸ”¹ Task 4.2: Transparency and Explainability in AI Models</h2>
  <ul>
    <li>Understand why <strong>transparency and explainability</strong> are key challenges in responsible AI.</li>
    <li>Define what makes a model <strong>transparent</strong> or <strong>explainable</strong>.</li>
    <li>Know tools that support explainability (e.g., SHAP, LIME, SageMaker Clarify).</li>
    <li>Evaluate <strong>tradeoffs</strong> between:
      <ul>
        <li>Model safety/security</li>
        <li>Model transparency/explainability</li>
      </ul>
    </li>
    <li>Understand how <strong>human-centric design</strong> supports better explainability in AI systems.</li>
  </ul>

</body>
</html>