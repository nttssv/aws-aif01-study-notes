# Task 4.2: Importance of Transparent and Explainable Models

## Understanding Responsible AI (Task 4.1)
- Understand what **Responsible AI** is and its core principles.
- Identify features of responsible AI systems (e.g., fairness, safety, accountability).
- Know tools that support responsible AI practices.
- Learn how responsible AI affects:
  - Model selection
  - Risk assessment
  - Dataset design and characteristics
- Understand **bias and variance** in responsible AI context.
- Use tools to:
  - Detect bias
  - Monitor model behavior
  - Evaluate trustworthiness and truthfulness

## Task 4.2: Transparency and Explainability in AI Models
- Understand why **transparency and explainability** are key challenges in responsible AI.
- Define what makes a model **transparent** or **explainable**.
- Know tools that support explainability (e.g., SHAP, LIME, SageMaker Clarify).
- Evaluate **tradeoffs** between:
  - Model safety/security
  - Model transparency/explainability
- Understand how **human-centric design** supports better explainability in AI systems.